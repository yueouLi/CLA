{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMIUyabeQBvRwHqa+q2MyNe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Instanz und Datensatz in Python**\n","#### CLA, Philipp Wicke, CIS/LMU | 20\"\n","---\n","\n","**Merkmale für Dokumente**\n","\n","Dokument: Tweet, Wikipedia-Artikel, Email, ...\n","\n"],"metadata":{"id":"3-a_RftSfzmF"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"SOvA4QRPtsQz","executionInfo":{"status":"ok","timestamp":1680432169267,"user_tz":-120,"elapsed":225,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}}},"outputs":[],"source":["doc1 = \"The raw text string of the document The tokenized text list of strings The token frequencies of the document A unique identifier for each document\""]},{"cell_type":"markdown","source":["Wie oft kommt jedes Wort vor (**Unigram**)?"],"metadata":{"id":"ti7ttjSUhXlU"}},{"cell_type":"code","source":["words = doc1.split()\n","word_counts = dict()\n","for word in words:\n","  if word in word_counts.keys():\n","    word_counts[word] +=1\n","  else:\n","    word_counts[word] = 1\n","\n","print(word_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSR7JIynhU8D","executionInfo":{"status":"ok","timestamp":1680432170402,"user_tz":-120,"elapsed":221,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}},"outputId":"1f27054c-7e86-40da-cf88-c374d23cf40b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{'The': 3, 'raw': 1, 'text': 2, 'string': 1, 'of': 3, 'the': 2, 'document': 3, 'tokenized': 1, 'list': 1, 'strings': 1, 'token': 1, 'frequencies': 1, 'A': 1, 'unique': 1, 'identifier': 1, 'for': 1, 'each': 1}\n"]}]},{"cell_type":"markdown","source":["`the` ist ein Merkmal und `2` der Merkmalswert\n","`The` ist ein anderes Merkmal mit dem Merkmalswert `3`\n","\n","Wir können nun fragen, wie oft kommt jedes **Bigram** vor? \n","\n","Also: `The raw`, `raw text`, `text string` etc."],"metadata":{"id":"VTN6vdDdiiwY"}},{"cell_type":"code","source":["from collections import Counter\n","print(\"Merkmals-Dictionary:\")\n","print(Counter(zip(words,words[1:])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZws7AkFis4i","executionInfo":{"status":"ok","timestamp":1680432274506,"user_tz":-120,"elapsed":201,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}},"outputId":"ff955cb2-9ffa-4c50-c321-10c3fe86bf0c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Merkmals-Dictionary:\n","Counter({('of', 'the'): 2, ('the', 'document'): 2, ('The', 'raw'): 1, ('raw', 'text'): 1, ('text', 'string'): 1, ('string', 'of'): 1, ('document', 'The'): 1, ('The', 'tokenized'): 1, ('tokenized', 'text'): 1, ('text', 'list'): 1, ('list', 'of'): 1, ('of', 'strings'): 1, ('strings', 'The'): 1, ('The', 'token'): 1, ('token', 'frequencies'): 1, ('frequencies', 'of'): 1, ('document', 'A'): 1, ('A', 'unique'): 1, ('unique', 'identifier'): 1, ('identifier', 'for'): 1, ('for', 'each'): 1, ('each', 'document'): 1})\n"]}]},{"cell_type":"markdown","source":["Wie oft kommt jedes Zeichen-Ngram (z.B. **Trigram**) vor?"],"metadata":{"id":"OFIE3JmrkijW"}},{"cell_type":"code","source":["words = doc1.split()\n","\n","trigrams = [word[i:i+3] for word in words for i in range(len(word)-2)]\n","\n","trigram_counts = {}\n","for trigram in trigrams:\n","    if trigram in trigram_counts:\n","        trigram_counts[trigram] += 1\n","    else:\n","        trigram_counts[trigram] = 1\n","\n","print(trigram_counts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkhMThbpjZd_","executionInfo":{"status":"ok","timestamp":1680432884650,"user_tz":-120,"elapsed":200,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}},"outputId":"5271434c-e5d8-47af-fa08-753167895598"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["{'The': 3, 'raw': 1, 'tex': 2, 'ext': 2, 'str': 2, 'tri': 2, 'rin': 2, 'ing': 2, 'the': 2, 'doc': 3, 'ocu': 3, 'cum': 3, 'ume': 3, 'men': 3, 'ent': 4, 'tok': 2, 'oke': 2, 'ken': 2, 'eni': 1, 'niz': 1, 'ize': 1, 'zed': 1, 'lis': 1, 'ist': 1, 'ngs': 1, 'fre': 1, 'req': 1, 'equ': 1, 'que': 2, 'uen': 1, 'enc': 1, 'nci': 1, 'cie': 1, 'ies': 1, 'uni': 1, 'niq': 1, 'iqu': 1, 'ide': 1, 'den': 1, 'nti': 1, 'tif': 1, 'ifi': 1, 'fie': 1, 'ier': 1, 'for': 1, 'eac': 1, 'ach': 1}\n"]}]},{"cell_type":"markdown","source":["Die verschiedenen erzeugten Merkmalswerte sind nichts anderes als Merkmalsvektoren:"],"metadata":{"id":"kdT9nSWjm0x4"}},{"cell_type":"code","source":["print(\"Unigram Merkmalsvektor: \", list(word_counts.values()))\n","print(\"Trigram Merkmalsvektor: \", list(trigram_counts.values()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iz7TF_Ehk-qa","executionInfo":{"status":"ok","timestamp":1680433017328,"user_tz":-120,"elapsed":4,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}},"outputId":"49258876-f61f-4bde-c9a7-deaf49523012"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Unigram Merkmalsvektor:  [3, 1, 2, 1, 3, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Trigram Merkmalsvektor:  [3, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}]},{"cell_type":"markdown","source":["---\n","\n","# Binärer Klassifikator: Trainings-/Testdaten in Python\n","\n","Schauen wir uns zunächst an wie wir eine Dateninstanz definieren können.\n","\n","*feature* : Merkmal\n","*instance* : Beispiel\n","*feature_count* : Merkmalswert\n","*label* : Klasse des Beispiels\n","\n","Wir haben eine Klasse die Trainingsbeispiele codiert. Dafür sind die Merkmale des Beispiels, welchen Wert der Merkmale und was ist die Klasse (das Label) des Beispiels."],"metadata":{"id":"W1Hjdp1Mq5J4"}},{"cell_type":"code","source":["class DataInstance:\n","  def __init__(self, feature_counts, label):\n","    # feature counts: dictionary (string -> int)\n","    self.feature_counts = feature_counts\n","    # label: True or False (binäre Klassifikation)\n","    self.label = label\n","\n","  @classmethod\n","  def from_list_of_feature_occurrences(cls, feature_list, label):\n","    # Eine Merkmalsliste kann auch bspw. ein dict sein wie [\"The\", \"raw\", \"tex\", ...]\n","\n","    feature_counts = dict()\n","    # TODO: Count how often a feature occurs in the list\n","    # ...\n","    return cls(feature_counts, label)"],"metadata":{"id":"9096OBbUm-Ru","executionInfo":{"status":"ok","timestamp":1680434256308,"user_tz":-120,"elapsed":3,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","  def __init__(self, instance_list, feature_set):\n","    # instance list: all instances in the data set\n","    self.instance_list = instance_list\n","    # feature_set: all features in the data set\n","    self.feature_set = feature_set\n","\n","    # ..."],"metadata":{"id":"xPkNoxS1sAp4","executionInfo":{"status":"ok","timestamp":1680434350690,"user_tz":-120,"elapsed":189,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["*   Welches idn die Merkmale, die in den meisten Instanzen vorkommen? Oft ist es sinnvoll, nur die häufigsten Merkmale (z.B. 1000) zu verwenden.\n","*   Ein Datensatz kann auf eine bestimmte Merkmalsmenge eingeschränkt werden. Andere Merkmale werden dann aus den Instanzen des Datensatzes entfernt.\n","\n"],"metadata":{"id":"1TNO408iuouE"}},{"cell_type":"code","source":["class Dataset:\n","  def __init__(self, instance_list, feature_set):\n","    self.instance_list = instance_list\n","    self.feature_set = feature_set\n","\n","  def get_topn_features(self, n):\n","    # ...\n","    pass\n","  def set_feature_set(self, feature_set):\n","    # ...\n","    pass"],"metadata":{"id":"Krj5EVtdu8Jv","executionInfo":{"status":"ok","timestamp":1680435076619,"user_tz":-120,"elapsed":318,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Weitere Methoden bieten sich an. \n","\n","* So zum Beispiel der Sanity-check: Welche Genauigkeit hätte die Vorhersage der häufigsten Kategorie? Also, wenn nur immer die häufigste Kategorie vorhergesagt wird (ohne irgendeine Überprüfung). Dies definiert unsere *baseline*, da unser Training besser sein sollte als lediglich immer die häufigste Kategorie auszuwählen.\n","\n","* Manche Lernalgorithmen verlangen mehrere Trainings-Iterationen, zwischen denen das Trainingsset neu permutiert (gemischt) werden sollte. Da das Trainingsset limitiert ist, kann eine `shuffle` Methode implementiert werden, damit bei jedem Trainingslauf (**Epoche**) zufäälig neu permutiert wird.\n"],"metadata":{"id":"1qw8O3z4vWff"}},{"cell_type":"code","source":["class Dataset:\n","  def __init__(self, instance_list, feature_set):\n","    self.instance_list = instance_list\n","    self.feature_set = feature_set\n","\n","  # ....\n","\n","  def most_frequent_sense_accuracy(self):\n","    # ...\n","    pass\n","  def shuffle(self):\n","    # ...\n","    pass"],"metadata":{"id":"rwD6NsN9vFo4","executionInfo":{"status":"ok","timestamp":1680435427938,"user_tz":-120,"elapsed":3,"user":{"displayName":"Philipp Wicke","userId":"01904971660225052168"}}},"execution_count":28,"outputs":[]}]}